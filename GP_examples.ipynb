{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Some examples of Gaussian Processes\n",
        "format:\n",
        "  pdf: default\n",
        "---"
      ],
      "id": "21726379"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports\n"
      ],
      "id": "4394360d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ],
      "id": "d4a47882",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "tfb = tfp.bijectors\n",
        "tfd = tfp.distributions\n",
        "tfk = tfp.math.psd_kernels\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sampling_seed = tfp.random.sanitize_seed(seed=146098)"
      ],
      "id": "0348aaa3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Effect of GP kernels\n"
      ],
      "id": "2d609fb7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictive_index_points_ = np.linspace(-1.2, 1.2, 200, dtype=np.float64)\n",
        "predictive_index_points_ = predictive_index_points_[..., np.newaxis]\n",
        "\n",
        "num_samples = 20\n",
        "\n",
        "gp = tfd.GaussianProcess(\n",
        "  kernel=tfk.ExponentiatedQuadratic(np.float64(1), np.float64(0.5)),\n",
        "  index_points=predictive_index_points_,\n",
        ")\n",
        "\n",
        "samples = gp.sample(num_samples, seed = sampling_seed)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "for i in range(num_samples):\n",
        "    plt.plot(\n",
        "        predictive_index_points_,\n",
        "        samples[i, :],\n",
        "        c=\"r\",\n",
        "        alpha=0.1 + 0.9 * (i + 1 == num_samples),\n",
        "        label=\"Posterior Sample\" if i == 0 else None,\n",
        "    )\n",
        "leg = plt.legend(loc=\"lower right\")\n",
        "for lh in leg.legend_handles:\n",
        "    lh.set_alpha(1)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.title(r\"Gaussian Process Realisation With the Squared Exponential Kernel\")\n",
        "plt.savefig(\"write_up/images/exponentiated_kernel.pdf\")\n",
        "plt.show()\n",
        "\n",
        "gp = tfd.GaussianProcess(\n",
        "  kernel=tfk.MaternOneHalf(np.float64(1), np.float64(0.5)),\n",
        "  index_points=predictive_index_points_,\n",
        ")\n",
        "\n",
        "samples = gp.sample(num_samples, seed = sampling_seed)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "for i in range(num_samples):\n",
        "    plt.plot(\n",
        "        predictive_index_points_,\n",
        "        samples[i, :],\n",
        "        c=\"r\",\n",
        "        alpha=0.1 + 0.9 * (i + 1 == num_samples),\n",
        "        label=\"Posterior Sample\" if i == 0 else None,\n",
        "    )\n",
        "leg = plt.legend(loc=\"lower right\")\n",
        "for lh in leg.legend_handles:\n",
        "    lh.set_alpha(1)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.title(r\"Gaussian Process Realisation with Matern Kernel $\\nu = 1/2$\")\n",
        "plt.savefig(\"write_up/images/maternonehalf_kernel.pdf\")\n",
        "plt.show()\n",
        "\n",
        "gp = tfd.GaussianProcess(\n",
        "  kernel=tfk.MaternThreeHalves(np.float64(1), np.float64(0.5)),\n",
        "  index_points=predictive_index_points_,\n",
        ")\n",
        "\n",
        "samples = gp.sample(num_samples, seed = sampling_seed)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "for i in range(num_samples):\n",
        "    plt.plot(\n",
        "        predictive_index_points_,\n",
        "        samples[i, :],\n",
        "        c=\"r\",\n",
        "        alpha=0.1 + 0.9 * (i + 1 == num_samples),\n",
        "        label=\"Posterior Sample\" if i == 0 else None,\n",
        "    )\n",
        "leg = plt.legend(loc=\"lower right\")\n",
        "for lh in leg.legend_handles:\n",
        "    lh.set_alpha(1)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.title(r\"Gaussian Process Realisation with Matern Kernel $\\nu = 3/2$\")\n",
        "plt.savefig(\"write_up/images/maternthreehalves_kernel.pdf\")\n",
        "plt.show()\n",
        "\n",
        "gp = tfd.GaussianProcess(\n",
        "  kernel=tfk.MaternFiveHalves(np.float64(1), np.float64(0.5)),\n",
        "  index_points=predictive_index_points_,\n",
        ")\n",
        "\n",
        "samples = gp.sample(num_samples, seed = sampling_seed)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "for i in range(num_samples):\n",
        "    plt.plot(\n",
        "        predictive_index_points_,\n",
        "        samples[i, :],\n",
        "        c=\"r\",\n",
        "        alpha=0.1 + 0.9 * (i + 1 == num_samples),\n",
        "        label=\"Posterior Sample\" if i == 0 else None,\n",
        "    )\n",
        "leg = plt.legend(loc=\"lower right\")\n",
        "for lh in leg.legend_handles:\n",
        "    lh.set_alpha(1)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.title(r\"Gaussian Process Realisation with Matern Kernel $\\nu = 5/2$\")\n",
        "plt.savefig(\"write_up/images/maternfivehalves_kernel.pdf\")\n",
        "plt.show()"
      ],
      "id": "1132692d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Changing length parameter no regression"
      ],
      "id": "c1ffcd2f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_samples = 50\n",
        "\n",
        "for ell in [0.5, 1, 2]:\n",
        "    gp = tfd.GaussianProcess(\n",
        "        kernel=tfk.ExponentiatedQuadratic(np.float64(1), np.float64(ell)),\n",
        "        index_points=predictive_index_points_,\n",
        "    )\n",
        "\n",
        "    samples = gp.sample(num_samples, seed=sampling_seed)\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    for i in range(num_samples):\n",
        "        plt.plot(\n",
        "            predictive_index_points_,\n",
        "            samples[i, :],\n",
        "            c=\"r\",\n",
        "            alpha=0.1 + 0.9 * (i + 1 == num_samples),\n",
        "            label=\"Posterior Sample\" if i == 0 else None,\n",
        "        )\n",
        "    leg = plt.legend(loc=\"lower right\")\n",
        "    for lh in leg.legend_handles:\n",
        "        lh.set_alpha(1)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"f(x)\")\n",
        "    plt.title(r\"Squared Exponential kernel with $\\ell = $\" + str(ell))\n",
        "    plt.savefig(\n",
        "        \"write_up/images/exponentiated_GP_ell_\" + str(int(ell * 10)) + \"_tenths.pdf\"\n",
        "    )\n",
        "    plt.show()"
      ],
      "id": "1fa4a7cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Changing length parameter with regression"
      ],
      "id": "2cf8532f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "flat_index = np.array([[-1], [0], [1]], dtype=np.float64)\n",
        "easy_obs = np.array([0, 0, 1], dtype=np.float64)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.scatter(flat_index[:, 0], easy_obs, label=\"Observations\")\n",
        "leg = plt.legend(loc=\"lower right\")\n",
        "for lh in leg.legend_handles:\n",
        "    lh.set_alpha(1)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.ylim(-2, 2)\n",
        "plt.title(\"Initial Points\")\n",
        "plt.savefig(\"write_up/images/flatish_GP_bare.pdf\")\n",
        "plt.show()"
      ],
      "id": "c517e7ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictive_index_points_ = np.linspace(-1.2, 1.2, 200, dtype=np.float64)\n",
        "predictive_index_points_ = predictive_index_points_[..., np.newaxis]\n",
        "num_samples = 50\n",
        "\n",
        "for ell in [0.5, 1, 2]:\n",
        "    gprm = tfd.GaussianProcessRegressionModel(\n",
        "        kernel=tfk.ExponentiatedQuadratic(np.float64(1), np.float64(ell)),\n",
        "        index_points=predictive_index_points_,\n",
        "        observation_index_points=flat_index,\n",
        "        observations=easy_obs,\n",
        "        predictive_noise_variance=0.0,\n",
        "    )\n",
        "\n",
        "    samples = gprm.sample(num_samples, seed = sampling_seed)\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    for i in range(num_samples):\n",
        "        plt.plot(\n",
        "            predictive_index_points_,\n",
        "            samples[i, :],\n",
        "            c=\"r\",\n",
        "            alpha=0.1 + 0.9 * (i + 1 == num_samples),\n",
        "            label=\"Posterior Sample\" if i == 0 else None,\n",
        "        )\n",
        "    plt.scatter(flat_index[:, 0], easy_obs, label=\"Observations\")\n",
        "    leg = plt.legend(loc=\"lower right\")\n",
        "    for lh in leg.legend_handles:\n",
        "        lh.set_alpha(1)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"f(x)\")\n",
        "    plt.ylim(-2, 2)\n",
        "    plt.title(r\"Squared Exponential Kernel with $\\ell = $\" + str(ell))\n",
        "    plt.savefig(\"write_up/images/flatish_GP_ell_\" + str(int(ell*10)) + \"_tenths.pdf\")\n",
        "    plt.show()"
      ],
      "id": "9fd33911",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Changing amplitude parameter"
      ],
      "id": "1b75f017"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for sigma in [0.5, 1, 2]:\n",
        "    gprm = tfd.GaussianProcessRegressionModel(\n",
        "        kernel=tfk.ExponentiatedQuadratic(np.float64(sigma), np.float64(1)),\n",
        "        index_points=predictive_index_points_,\n",
        "        observation_index_points=flat_index,\n",
        "        observations=easy_obs,\n",
        "        predictive_noise_variance=0.0,\n",
        "    )\n",
        "\n",
        "    samples = gprm.sample(num_samples, seed = sampling_seed)\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    for i in range(num_samples):\n",
        "        plt.plot(\n",
        "            predictive_index_points_,\n",
        "            samples[i, :],\n",
        "            c=\"r\",\n",
        "            alpha=0.1 + 0.9 * (i + 1 == num_samples),\n",
        "            label=\"Posterior Sample\" if i == 0 else None,\n",
        "        )\n",
        "    plt.scatter(flat_index[:, 0], easy_obs, label=\"Observations\")\n",
        "    leg = plt.legend(loc=\"lower right\")\n",
        "    for lh in leg.legend_handles:\n",
        "        lh.set_alpha(1)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"f(x)\")\n",
        "    plt.ylim(-2, 2)\n",
        "    plt.title(r\"Function estimation with $\\sigma = $\" + str(sigma))\n",
        "    plt.savefig(\"write_up/images/flatish_GP_sigma_\" + str(sigma*10) + \"_tenths.pdf\")\n",
        "    plt.show()"
      ],
      "id": "9ada0963",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Matern kernels"
      ],
      "id": "6f4d07c3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictive_index_points_ = np.linspace(-1.2, 1.2, 400, dtype=np.float64)\n",
        "predictive_index_points_ = predictive_index_points_[..., np.newaxis]\n",
        "\n",
        "for nu in [0.5, 1.5, 2.5]:\n",
        "    gprm = tfd.GaussianProcessRegressionModel(\n",
        "        kernel=tfk.GeneralizedMatern(nu, np.float64(1), np.float64(1)),\n",
        "        index_points=predictive_index_points_,\n",
        "        observation_index_points=flat_index,\n",
        "        observations=easy_obs,\n",
        "        predictive_noise_variance=0.0,\n",
        "    )\n",
        "\n",
        "    samples = gprm.sample(num_samples / 2, seed=sampling_seed)\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    for i in range(int(num_samples / 2)):\n",
        "        plt.plot(\n",
        "            predictive_index_points_,\n",
        "            samples[i, :],\n",
        "            c=\"r\",\n",
        "            alpha=0.1 + 0.9 * (i + 1 == int(num_samples / 2)),\n",
        "            label=\"Posterior Sample\" if i == 0 else None,\n",
        "        )\n",
        "    plt.scatter(flat_index[:, 0], easy_obs, label=\"Observations\", alpha=1)\n",
        "    leg = plt.legend(loc=\"lower right\")\n",
        "    for lh in leg.legend_handles:\n",
        "        lh.set_alpha(1)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"f(x)\")\n",
        "    plt.ylim(-2, 2)\n",
        "    plt.title(r\"Matern Kernel with $\\nu = $\" + str(nu))\n",
        "    plt.savefig(\"write_up/images/flatish_GP_matern_\" + str(nu * 10) + \"_tenths.pdf\")\n",
        "    plt.show()"
      ],
      "id": "7e1df6dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GP for Noiseless Cubic Target Function\n"
      ],
      "id": "6db071cb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_seed = np.random.default_rng(seed=591)  # For replicability\n",
        "\n",
        "\n",
        "def cub_fn(x):\n",
        "  return x[..., 0] * (x[..., 0] - 1) * (x[..., 0] + 1)\n",
        "\n",
        "ind_range = 10\n",
        "cub_index_vals = np.expand_dims(  # this makes the size of the sample (3,1)\n",
        "  my_seed.uniform(low=-1.0, high=1.0, size=ind_range), axis=-1  # last axis\n",
        ")\n",
        "\n",
        "cub_obs_vals = cub_fn(cub_index_vals)\n",
        "\n",
        "my_GP = tfd.GaussianProcess(\n",
        "  kernel=tfk.ExponentiatedQuadratic(\n",
        "    amplitude=tf.Variable(1.0, dtype=np.float64, name=\"amplitude\"),\n",
        "    length_scale=tf.Variable(1.0, dtype=np.float64, name=\"length_scale\"),\n",
        "  ),\n",
        "  index_points=cub_index_vals,\n",
        ")\n",
        "\n",
        "print(my_GP.trainable_variables[1])\n",
        "\n",
        "Adam_optim = tf.optimizers.Adam()"
      ],
      "id": "894a94e4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@tf.function()\n",
        "def optimize():\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = -my_GP.log_prob(cub_obs_vals)\n",
        "  grads = tape.gradient(loss, my_GP.trainable_variables)\n",
        "  Adam_optim.apply_gradients(zip(grads, my_GP.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "\n",
        "num_iters = 7000\n",
        "\n",
        "lls_ = np.zeros(num_iters, np.float64)\n",
        "for i in range(num_iters):\n",
        "  loss = optimize()\n",
        "  lls_[i] = loss\n",
        "\n",
        "amp_fin = my_GP.trainable_variables[0].numpy()\n",
        "len_fin = my_GP.trainable_variables[1].numpy()\n",
        "\n",
        "print(\"Trained parameters:\")\n",
        "print(\"amplitude: {}\".format(amp_fin))\n",
        "print(\"length_scale: {}\".format(len_fin))"
      ],
      "id": "6f333db3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(7, 4))\n",
        "plt.plot(lls_)\n",
        "plt.xlabel(\"Training iteration\")\n",
        "plt.ylabel(\"Log likelihood\")\n",
        "plt.show()"
      ],
      "id": "ed1e70da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictive_index_points_ = np.linspace(-1.2, 1.2, 200, dtype=np.float64)\n",
        "\n",
        "# Reshape to [200, 1] -- 1 is the dimensionality of the feature space.\n",
        "predictive_index_points_ = predictive_index_points_[..., np.newaxis]\n",
        "\n",
        "optimized_kernel = tfk.ExponentiatedQuadratic(amp_fin, len_fin)\n",
        "num_samples = 20\n",
        "\n",
        "for ind in range(ind_range):\n",
        "  gprm = tfd.GaussianProcessRegressionModel(\n",
        "    kernel=optimized_kernel,\n",
        "    index_points=predictive_index_points_,\n",
        "    observation_index_points=cub_index_vals[range(ind+1)],\n",
        "    observations=cub_obs_vals[range(ind+1)],\n",
        "    predictive_noise_variance=0.0,\n",
        "  )\n",
        "\n",
        "  samples = gprm.sample(num_samples, seed = sampling_seed)\n",
        "\n",
        "  plt.figure(figsize=(7, 4))\n",
        "  plt.plot(predictive_index_points_, cub_fn(predictive_index_points_),\n",
        "    label='True fn')\n",
        "  for i in range(num_samples):\n",
        "    plt.plot(predictive_index_points_, samples[i, :], c='r', alpha=.2,\n",
        "      label='Posterior Sample' if i == 0 else None)\n",
        "  plt.scatter(cub_index_vals[range(ind+1)], cub_obs_vals[range(ind+1)],\n",
        "    label='Observations')\n",
        "  leg = plt.legend(loc='upper right')\n",
        "  for lh in leg.legend_handles:\n",
        "    lh.set_alpha(1)\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.ylabel(\"f(x)\")\n",
        "  plt.ylim(-1, 1)\n",
        "  # plt.title(r\"Function estimation with GP\")\n",
        "  plt.savefig(\"write_up/images/cub_GP_\" + str(ind + 1) + \"_iters.pdf\")\n",
        "  plt.show()"
      ],
      "id": "256a9e0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GP for Cubic Target Function with Noise\n"
      ],
      "id": "2a035c0c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_obs_err = 20\n",
        "\n",
        "my_seed_err = np.random.default_rng(seed=914)\n",
        "\n",
        "# cub_obs_vals_err = cub_obs_vals + my_seed.normal(\n",
        "#         scale=0.1, size=num_obs_err\n",
        "#     )\n",
        "\n",
        "def cub_fn_err(x):\n",
        "    return x[..., 0] * (x[..., 0] - 1) * (x[..., 0] + 1) + my_seed_err.normal(\n",
        "        scale=0.1, size=x.shape[0]\n",
        "    )\n",
        "\n",
        "\n",
        "cub_obs_vals_err = cub_fn_err(cub_index_vals)\n",
        "\n",
        "for ind in range(ind_range):\n",
        "    gprm = tfd.GaussianProcessRegressionModel(\n",
        "        kernel=optimized_kernel,\n",
        "        index_points=predictive_index_points_,\n",
        "        observation_index_points=cub_index_vals[range(ind + 1)],\n",
        "        observations=cub_obs_vals_err[range(ind + 1)],\n",
        "        observation_noise_variance=tf.Variable(\n",
        "            0.01, dtype=np.float64, name=\"observation_noise_variance_err\"\n",
        "        ),\n",
        "        predictive_noise_variance=0.0,\n",
        "    )\n",
        "\n",
        "    samples = gprm.sample(num_samples, seed=sampling_seed)\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(\n",
        "        predictive_index_points_, cub_fn(predictive_index_points_), label=\"True fn\"\n",
        "    )\n",
        "    for i in range(num_samples):\n",
        "        plt.plot(\n",
        "            predictive_index_points_,\n",
        "            samples[i, :],\n",
        "            c=\"r\",\n",
        "            alpha=0.2,\n",
        "            label=\"Posterior Sample\" if i == 0 else None,\n",
        "        )\n",
        "    plt.scatter(\n",
        "        cub_index_vals[range(ind + 1)],\n",
        "        cub_obs_vals_err[range(ind + 1)],\n",
        "        label=\"Observations\",\n",
        "    )\n",
        "    leg = plt.legend(loc=\"upper right\")\n",
        "    for lh in leg.legend_handles:\n",
        "        lh.set_alpha(1)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"f(x)\")\n",
        "    plt.ylim(-1, 1)\n",
        "    # plt.title(r\"Function estimation with GP\")\n",
        "    plt.savefig(\"write_up/images/cub_GP_err_\" + str(ind + 1) + \"_iters.pdf\")\n",
        "    plt.show()"
      ],
      "id": "deadd12f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "UCB_index_points = np.array([[0.0]])\n",
        "UCB_obs_points = cub_fn_err(UCB_index_points)\n",
        "\n",
        "next_point = tfp.util.TransformedVariable(\n",
        "    initial_value=0.5,\n",
        "    bijector=tfb.Sigmoid(np.float64(-1.0), np.float64(1.0)),\n",
        "    dtype=np.float64,\n",
        ")\n",
        "\n",
        "UCB_GP_reg = tfd.GaussianProcessRegressionModel(\n",
        "    kernel=optimized_kernel,\n",
        "    observation_index_points=UCB_index_points,\n",
        "    observations=UCB_obs_points,\n",
        "    observation_noise_variance=tf.Variable(\n",
        "        0.01, dtype=np.float64, name=\"observation_noise_variance_err\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "def UCB_loss():\n",
        "    x = tf.reshape(next_point, [1, 1])\n",
        "    mean_t = UCB_GP_reg.mean_fn(x)\n",
        "    std_t = UCB_GP_reg.stddev(index_points=x)\n",
        "    return tf.squeeze(mean_t - std_t)\n",
        "\n",
        "def update_var_UCB():\n",
        "    optimizer_fast = tf.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "    @tf.function(autograph=False, jit_compile=False)\n",
        "    def opt_var():\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = UCB_loss()\n",
        "        grads = tape.gradient(loss, next_point.trainable_variables)\n",
        "        optimizer_fast.apply_gradients(zip(grads, next_point.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    max_iters = 10000\n",
        "\n",
        "    lls_ = np.zeros(max_iters, np.float64)\n",
        "    tolerance = 1e-6  # Set your desired tolerance level\n",
        "    previous_loss = float(\"inf\")\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        loss = opt_var()\n",
        "        lls_[i] = loss\n",
        "\n",
        "        # Check if change in loss is less than tolerance\n",
        "        if abs(loss - previous_loss) < tolerance:\n",
        "            print(f\"Acquisition function convergence reached at iteration {i+1}.\")\n",
        "            break\n",
        "\n",
        "        previous_loss = loss\n",
        "\n",
        "UCB_loss()"
      ],
      "id": "8d05f1fc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for t in range(ind_range):\n"
      ],
      "id": "c283060c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Adam_optim = tf.optimizers.Adam() # somehow need this again? maybe when you do the optimize function it stores info?\n",
        "\n",
        "@tf.function()\n",
        "def optimize_err():\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = -my_GP_err.log_prob(cub_obs_vals_err)\n",
        "  grads = tape.gradient(loss, my_GP_err.trainable_variables)\n",
        "  Adam_optim.apply_gradients(zip(grads, my_GP_err.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "\n",
        "num_iters_err = 5000\n",
        "\n",
        "lls_err = np.zeros(num_iters_err, np.float64)\n",
        "for i in range(num_iters_err):\n",
        "  loss_err = optimize_err()\n",
        "  lls_err[i] = loss_err\n",
        "\n",
        "amp_fin_err = my_GP_err.trainable_variables[0].numpy()\n",
        "len_fin_err = my_GP_err.trainable_variables[1].numpy()\n",
        "obs_var_fin_err = my_GP_err.trainable_variables[2].numpy()\n",
        "\n",
        "print('Trained parameters:')\n",
        "print('amplitude_err: {}'.format(amp_fin))\n",
        "print('length_scale_err: {}'.format(len_fin))\n",
        "print('observation_noise_variance_err: {}'.format(obs_var_fin_err))\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.plot(lls_err)\n",
        "plt.xlabel(\"Training iteration\")\n",
        "plt.ylabel(\"Log likelihood\")\n",
        "plt.show()"
      ],
      "id": "4faec98c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimized_kernel_err = tfk.ExponentiatedQuadratic(amp_fin_err, len_fin_err)\n",
        "gprm_err = tfd.GaussianProcessRegressionModel(\n",
        "  kernel=optimized_kernel_err,\n",
        "  index_points=predictive_index_points_,\n",
        "  observation_index_points=cub_index_vals_err,\n",
        "  observations=cub_obs_vals_err,\n",
        "  observation_noise_variance=obs_var_fin_err,\n",
        "  predictive_noise_variance=0.)\n",
        "\n",
        "num_samples_err = 50\n",
        "samples_err = gprm_err.sample(num_samples_err, seed = sampling_seed)"
      ],
      "id": "ee29e420",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(7, 4))\n",
        "plt.plot(predictive_index_points_, cub_fn(predictive_index_points_),\n",
        "  label='True fn')\n",
        "plt.scatter(cub_index_vals_err[:, 0], cub_obs_vals_err,\n",
        "  label='Observations')\n",
        "for i in range(num_samples_err):\n",
        "  plt.plot(predictive_index_points_, samples_err[i, :], c='r', alpha=.1,\n",
        "    label='Posterior Sample' if i == 0 else None)\n",
        "leg = plt.legend(loc='upper right')\n",
        "for lh in leg.legend_handles:\n",
        "  lh.set_alpha(1)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.show()"
      ],
      "id": "e591e14a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GP with Quadratic Mean Function for Cubic Target Function\n"
      ],
      "id": "4b5498e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_obs_quad=4\n",
        "\n",
        "my_seed_quad=np.random.default_rng(seed=687)\n",
        "\n",
        "\n",
        "cub_index_vals_quad = np.expand_dims( # this makes the size of the sample (3,1)\n",
        "  my_seed_quad.uniform(low=-1., high=1., size=num_obs_quad),\n",
        "  axis=-1 # last axis\n",
        ")\n",
        "\n",
        "cub_obs_vals_quad = cub_fn(cub_index_vals_quad)\n",
        "\n",
        "def custom_mean_fn(x):\n",
        "  # You can define your own mean function here\n",
        "  # For example, a linear mean function: return 2.0 * x\n",
        "  return - x[..., 0]**2\n",
        "\n",
        "my_GP_quad = tfd.GaussianProcess(\n",
        "  kernel=tfk.ExponentiatedQuadratic(\n",
        "    amplitude=tf.Variable(1., dtype=np.float64, name=\"amplitude_quad\"),\n",
        "    length_scale=tf.Variable(1., dtype=np.float64, name=\"length_scale_quad\")\n",
        "  ),\n",
        "  index_points=cub_index_vals_quad,\n",
        "  mean_fn=custom_mean_fn)\n",
        "\n",
        "print(my_GP_quad.trainable_variables)"
      ],
      "id": "28a74178",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Adam_optim = tf.optimizers.Adam() # somehow need this again? maybe when you do the optimize function it stores info?\n",
        "\n",
        "@tf.function()\n",
        "def optimize_quad():\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = -my_GP_quad.log_prob(cub_obs_vals_quad)\n",
        "  grads = tape.gradient(loss, my_GP_quad.trainable_variables)\n",
        "  Adam_optim.apply_gradients(zip(grads, my_GP_quad.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "\n",
        "num_iters_quad = 5000\n",
        "\n",
        "lls_quad = np.zeros(num_iters_quad, np.float64)\n",
        "for i in range(num_iters_quad):\n",
        "  loss_quad = optimize_quad()\n",
        "  lls_quad[i] = loss_quad\n",
        "\n",
        "amp_fin_quad = my_GP_quad.trainable_variables[0].numpy()\n",
        "len_fin_quad = my_GP_quad.trainable_variables[1].numpy()\n",
        "\n",
        "print('Trained parameters:')\n",
        "print('amplitude_quad: {}'.format(amp_fin))\n",
        "print('length_scale_quad: {}'.format(len_fin))\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.plot(lls_quad)\n",
        "plt.xlabel(\"Training iteration\")\n",
        "plt.ylabel(\"Log likelihood\")\n",
        "plt.show()"
      ],
      "id": "ed18a05a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimized_kernel_quad = tfk.ExponentiatedQuadratic(amp_fin_quad, len_fin_quad)\n",
        "gprm_quad = tfd.GaussianProcessRegressionModel(\n",
        "  kernel=optimized_kernel_quad,\n",
        "  index_points=predictive_index_points_,\n",
        "  observation_index_points=cub_index_vals_quad,\n",
        "  observations=cub_obs_vals_quad,\n",
        "  predictive_noise_variance=0.,\n",
        "  mean_fn=custom_mean_fn)\n",
        "\n",
        "num_samples_quad = 50\n",
        "samples_quad = gprm_quad.sample(num_samples_quad, seed = sampling_seed)"
      ],
      "id": "867df582",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(7, 4))\n",
        "plt.plot(predictive_index_points_, cub_fn(predictive_index_points_),\n",
        "  label='True fn')\n",
        "plt.scatter(cub_index_vals_quad[:, 0], cub_obs_vals_quad,\n",
        "  label='Observations')\n",
        "for i in range(num_samples_quad):\n",
        "  plt.plot(predictive_index_points_, samples_quad[i, :], c='r', alpha=.1,\n",
        "    label='Posterior Sample' if i == 0 else None)\n",
        "leg = plt.legend(loc='upper right')\n",
        "for lh in leg.legend_handles:\n",
        "  lh.set_alpha(1)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.show()"
      ],
      "id": "61957439",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GP for 2 observations with Differing Observation Variance\n"
      ],
      "id": "32b1fe0a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def varying_variance(num_low, num_high, var_low, var_high):\n",
        "  seed_low=np.random.default_rng(seed=973)\n",
        "  seed_high=np.random.default_rng(seed=8973)\n",
        "  seed_other=np.random.default_rng(seed=873)\n",
        "\n",
        "  samples_low_ = seed_low.normal(scale = np.sqrt(var_low), size = num_low) #+ np.ones(num_low)\n",
        "  samples_high_ = seed_high.normal(scale = np.sqrt(var_high), size = num_high) + np.ones(num_high)\n",
        "\n",
        "  x_indices_ = np.expand_dims( # this makes the size of the sample (3,1)\n",
        "    np.concatenate((np.zeros(num_low), np.ones(num_high))),\n",
        "    axis=-1 # last axis\n",
        "    )\n",
        "  y_vals_ = np.concatenate((samples_low_, samples_high_))\n",
        "\n",
        "  GP_ = tfd.GaussianProcess(\n",
        "    kernel=tfk.ExponentiatedQuadratic(\n",
        "      amplitude=tf.Variable(1., dtype=np.float64, name=\"amplitude\"),\n",
        "      length_scale=tf.Variable(1., dtype=np.float64, name=\"length_scale\")\n",
        "    ),\n",
        "    observation_noise_variance=tf.Variable(1., dtype=np.float64, name=\"observation_noise_variance\"),\n",
        "    index_points=x_indices_\n",
        "  )\n",
        "\n",
        "  optimizer_ = tf.optimizers.Adam() # somehow need this again? maybe when you do the optimize function it stores info?\n",
        "\n",
        "  @tf.function()\n",
        "  def optimize_():\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss = -GP_.log_prob(y_vals_)\n",
        "    grads = tape.gradient(loss, GP_.trainable_variables)\n",
        "    optimizer_.apply_gradients(zip(grads, GP_.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "  num_iters_ = 5000\n",
        "\n",
        "  lls_ = np.zeros(num_iters_, np.float64)\n",
        "  for i in range(num_iters_):\n",
        "    loss_ = optimize_()\n",
        "    lls_[i] = loss_\n",
        "\n",
        "  amp_fin_ = GP_.trainable_variables[0].numpy()\n",
        "  len_fin_ = GP_.trainable_variables[1].numpy()\n",
        "  noise_fin_ = GP_.trainable_variables[2].numpy()\n",
        "\n",
        "  predictive_index_points_ = np.linspace(-.2, 1.2, 20, dtype=np.float64)\n",
        "  # Reshape to [200, 1] -- 1 is the dimensionality of the feature space.\n",
        "  predictive_index_points_ = predictive_index_points_[..., np.newaxis]\n",
        "\n",
        "  optimized_kernel_ = tfk.ExponentiatedQuadratic(amp_fin_, len_fin_)\n",
        "  gprm_ = tfd.GaussianProcessRegressionModel(\n",
        "    kernel=optimized_kernel_,\n",
        "    index_points=predictive_index_points_,\n",
        "    observation_index_points=x_indices_,\n",
        "    observations=y_vals_,\n",
        "    observation_noise_variance=noise_fin_,\n",
        "    predictive_noise_variance=0.)\n",
        "\n",
        "  num_fn_samples_ = 50\n",
        "  tf.random.set_seed(25626)\n",
        "  samples_ = gprm_.sample(num_fn_samples_, seed = sampling_seed)\n",
        "  plt.figure(figsize=(7, 4))\n",
        "  plt.scatter(x_indices_[:, 0], y_vals_,\n",
        "    label='Observations')\n",
        "  for i in range(num_fn_samples_):\n",
        "    plt.plot(predictive_index_points_, samples_[i, :], c='r', alpha=.1,\n",
        "      label='Posterior Sample' if i == 0 else None)\n",
        "  leg = plt.legend(loc='upper left')\n",
        "  for lh in leg.legend_handles:\n",
        "    lh.set_alpha(1)\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.ylabel(\"f(x)\")\n",
        "  plt.show()\n",
        "\n",
        "  return amp_fin_, len_fin_, noise_fin_\n",
        "\n",
        "varying_variance(100, 2, 0.01, 1)"
      ],
      "id": "ced9b48a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimenting with Differing Numbers of Observations\n"
      ],
      "id": "b6f01a0a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "varying_variance(3, 3, 0.01, 1)\n",
        "varying_variance(3, 10, 0.01, 1)\n",
        "varying_variance(3, 100, 0.01, 1)\n",
        "varying_variance(10, 3, 0.01, 1)\n",
        "varying_variance(100, 3, 0.01, 1)"
      ],
      "id": "8f0596da",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}